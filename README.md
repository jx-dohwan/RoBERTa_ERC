
## ğŸ’¡í”„ë¡œì íŠ¸ ì†Œê°œ

#### 1ï¸âƒ£ ì£¼ì œ : ëŒ€í™”ì† ê°ì •ì¸ì‹<br>
#### 2ï¸âƒ£ ì„¤ëª… : [CoMPM ë…¼ë¬¸](https://arxiv.org/pdf/2108.11626v3.pdf)ì„ ê¸°ë°˜ìœ¼ë¡œ ERC ëª¨ë¸ì„ êµ¬í˜„<br> 
#### 3ï¸âƒ£ ëª¨ë¸ : Hugging Face [roberta-base](https://huggingface.co/roberta-base) ëª¨ë¸ ì‚¬ìš©í•˜ì—¬ ì§„í–‰<br><br>

### í•´ë‹¹ í”„ë¡œì íŠ¸ì— ê´€í•œ ìì„¸í•œ ì‚¬í•­ì€ ë¸”ë¡œê·¸ì— ì •ë¦¬í•´ ë†“ì•˜ë‹¤.
- [RoBERTaë¥¼ í™œìš©í•œ ëŒ€í™” ì† ê°ì • ì¸ì‹_1(feat.ë…¼ë¬¸, ë² ì´ìŠ¤ë¼ì¸)]https://velog.io/@jx7789/RoBERTa%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%8C%80%ED%99%94-%EC%86%8D-%EA%B0%90%EC%A0%95%EC%9D%B8%EC%8B%9D1feat.%EB%85%BC%EB%AC%B8-%EB%AA%A8%EB%8D%B8%EC%86%8C%EA%B0%9C-%ED%8E%B8)
- [RoBERTaë¥¼ í™œìš©í•œ ëŒ€í™” ì† ê°ì • ì¸ì‹_2(feat.ë°ì´í„°)](https://velog.io/@jx7789/RoBERTa%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%8C%80%ED%99%94-%EC%86%8D-%EA%B0%90%EC%A0%95-%EC%9D%B8%EC%8B%9D2feat.%EB%8D%B0%EC%9D%B4%ED%84%B0)
- [RoBERTaë¥¼ í™œìš©í•œ ëŒ€í™” ì† ê°ì • ì¸ì‹_3(ft.ëª¨ë¸í¸)]https://velog.io/@jx7789/RoBERTa%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%8C%80%ED%99%94-%EC%86%8D-%EA%B0%90%EC%A0%95-%EC%9D%B8%EC%8B%9D3ft.%EB%AA%A8%EB%8D%B8%ED%8E%B8)
- [RoBERTaë¥¼ í™œìš©í•œ ëŒ€í™” ì† ê°ì • ì¸ì‹_4(feat.í•™ìŠµí¸)](https://velog.io/@jx7789/RoBERTa%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%8C%80%ED%99%94-%EC%86%8D-%EA%B0%90%EC%A0%95-%EC%9D%B8%EC%8B%9D4feat.%ED%95%99%EC%8A%B5%ED%8E%B8)
- [RoBERTaë¥¼ í™œìš©í•œ ëŒ€í™” ì† ê°ì • ì¸ì‹_5(feat.í‰ê°€í¸)](https://velog.io/@jx7789/RoBERTa%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%8C%80%ED%99%94-%EC%86%8D-%EA%B0%90%EC%A0%95-%EC%9D%B8%EC%8B%9D5feat.%ED%8F%89%EA%B0%80%ED%8E%B8)

## CoMPM ë…¼ë¬¸ ì†Œê°œ
#### CoM(context module) : ì…ë ¥ìœ¼ë¡œëŠ” ëŒ€í™”ì˜ ë°œí™”ë“¤ì´ ì „ë¶€ ë“¤ì–´ê°„ë‹¤.
#### PM(pre-trained memory module) : CSKì™€ ê°™ì´ context-independentë°œí™”ì˜ featureì„ ë‹´ì•„ë‚´ê¸° ìœ„í•¨ì´ë‹¤. <br><br>

![](img/ComPM.png)
<Br><br>
### ë¶€ì—°ì„¤ëª…
- ê° ë°œí™”ì˜ featureëŠ” CLS vectorë¡œ ì¶”ì¶œí•œë‹¤. 
- ì´ vectorë¥¼ GRUë¥¼ ì´ìš©í•˜ì—¬ í•˜ë‚˜ì˜ vectorë¡œ ë§Œë“ ë‹¤.
- Attention-based ê²°í•©ì€ ì„±ëŠ¥ì´ ë–¨ì–´ì§„ë‹¤.
- speaker trackingë§Œ í•œë‹¤.
- Listener trackingëŠ” í° íš¨ê³¼ê°€ ì—†ë‹¤.
- CoMê³¼ PMì˜ feature vectorì˜ dimensionì´ ë‹¤ë¥´ë©´ Wpì„ ì´ìš©í•˜ì—¬ ë§ì¶°ì¤€ë‹¤.

---
## ë² ì´ìŠ¤ë¼ì¸ë¸ëª¨ë¸(ft.v1)
### 1. Train 

```
!pip install transformers==4.25.1
!pip install sklearn

!python train.py
```

### 2. Test
```
import torch
from dataset import data_loader
from torch.utils.data import DataLoader

test_dataset = data_loader('./data/test_sent_emo.csv')
test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4, collate_fn=test_dataset.collate_fn)

from model import ERC_model
clsNum = len(test_dataset.emoList)
erc_model = ERC_model(clsNum).cuda()
model_path = './model.bin'
erc_model.load_state_dict(torch.load(model_path))
erc_model.eval()
print('')
```

---
## ëª¨ë¸_v2
### 1. args
```
# í•„ìˆ˜ì§€ì •
p.add_argument('--train_fn', required=True)
p.add_argument('--dev_fn', required=True)
p.add_argument('--test_fn', required=True)
p.add_argument('--save_fn', required=True)

# ê¸°íƒ€ì§€ì •
p.add_argument('--epochs', type=int, default=5)
p.add_argument('--training_steps', type=int, required=False)
p.add_argument('--warmup_steps', type=int, required=False)
p.add_argument('--grad_norm', type=int, default=10)
p.add_argument('--num_workers', type=int, default=4)
p.add_argument('--lr', type=float, default=1e-6)  
```

### 2. train

```
!pip install transformers==4.25.1
!pip install sklearn

!python train_v2.py --train_fn 'data/train.json' --dev_fn 'data/valid.json' --test_fn 'data/valid.json' --save_fn 'checkpoint'
```
### 3. test
```
from error_sample import ErrorSamples 

data_path = "valid.json"
model_path = "checkpoint/checkpoint-4/ERC_model.bin"

error_samples, acc, pred_list, label_list, test_dataset = ErrorSamples(data_path, model_path)
```
#### 1) local test
```
# error sample í™•ì¸
import random
random_error_samples = random.sample(error_samples, 10)
     
for random_error_sample in random_error_samples:
    batch_padding_token, true_label, pred_label = random_error_sample
    print('--------------------------------------------------------')
    print("ì…ë ¥ ë¬¸ì¥ë“¤: ", test_dataset.tokenizer.decode(batch_padding_token.squeeze(0).tolist()))
    print("ì •ë‹µ ê°ì •: ", test_dataset.emoList[true_label])
    print("ì˜ˆì¸¡ ê°ì •: ", test_dataset.emoList[pred_label])
```
#### 2) global test
```
true_emotion = []
pred_emotion = []
for error_sample in error_samples:
    batch_padding_token, true_label, pred_label = error_sample
    input_sentence = test_dataset.tokenizer.decode(batch_padding_token.squeeze(0).tolist())
    true_emotion.append(test_dataset.emoList[true_label])
    pred_emotion.append(test_dataset.emoList[pred_label])
    
    
from collections import Counter

data = Counter(true_emotion) # ì—¬ê¸°ì— true_emotionì„ ë„£ì„ì§€ pred_emotionì„ ë„£ì„ì§€ ê²°ì •í•¨ë…€ ëœë‹¤.
emotions = list(data.keys())
counts = list(data.values())

# ë§‰ëŒ€ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
fig, ax = plt.subplots()
ax.bar(emotions, counts) # xì¶•ì—ëŠ” ê°ì • ì¹´í…Œê³ ë¦¬, yì¶•ì—ëŠ” ë¹ˆë„ìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë§‰ëŒ€ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°

ax.set_xlabel('ê°ì •')
ax.set_ylabel('ë¹ˆë„')
ax.set_title('ê°ì •ì˜ ë¶„í¬')

plt.show()    
```

---
## ğŸ—“ï¸ í”„ë¡œì íŠ¸ ê°œì„  ì§„í–‰

|ê°œì„  ì„œë¹„ìŠ¤|ì§„í–‰ì‚¬í•­(%)|
|:----------:|:------:|
|í•œêµ­ì–´ ë°ì´í„° ì‚¬ìš©|100%|
|speaker êµ¬ë¶„|100%|
|CLS í† í° ìœ„ì¹˜ë³€ê²½ |ë¶ˆí•„ìš”|
|special tokenìœ¼ë¡œ ì˜ˆì¸¡í•  ë°œí™” ì¶”ê°€|100%|
|ê°ì •ê°„ì˜ ìƒê´€ê´€ê³„ ê³ ë ¤|ë¶ˆí•„ìš”|
|ëª¨ë¸ ì €ì¥ì‹œ ë‹¤ë¥¸ ìš”ì†Œ ì¶”ê°€|100%|



---
